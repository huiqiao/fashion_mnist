{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36cbaf55-9548-43c3-aeef-f10ed36d8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, Flatten \n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eb1d68f-a668-4dd2-b0c5-ae411a110148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transformations with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Assuming grayscale images\n",
    "])\n",
    "\n",
    "# Validation transformations without augmentation\n",
    "validate_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92953373-adfe-48a4-9358-f6a1a52d373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "full_train_set = datasets.FashionMNIST(root='./data', train=True, download=True, transform=validate_transform)\n",
    "test_set = datasets.FashionMNIST(root='./data', train=False, download=True, transform=validate_transform)\n",
    "\n",
    "# Split the training dataset\n",
    "train_size = int(0.9 * len(full_train_set))\n",
    "validate_size = len(full_train_set) - train_size\n",
    "train_set, validate_set = random_split(full_train_set, [train_size, validate_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "validate_loader = DataLoader(validate_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "576aeda8-b42d-4dbe-b6d0-43eeb0c41760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.network = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout(0.25),   # Dropout with 25% probability\n",
    "            Flatten(),\n",
    "            Linear(64 * 7 * 7, 128),  # An intermediate dense layer\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(0.25),  # Higher dropout before the final layer\n",
    "            Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de1ab11f-9b4d-437d-a933-2f133b29e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.834 K parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Net                                      [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 10]                   --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 28, 28]           64\n",
       "│    └─ReLU: 2-3                         [1, 32, 28, 28]           --\n",
       "│    └─MaxPool2d: 2-4                    [1, 32, 14, 14]           --\n",
       "│    └─Conv2d: 2-5                       [1, 64, 14, 14]           18,496\n",
       "│    └─BatchNorm2d: 2-6                  [1, 64, 14, 14]           128\n",
       "│    └─ReLU: 2-7                         [1, 64, 14, 14]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 64, 7, 7]             --\n",
       "│    └─Dropout: 2-9                      [1, 64, 7, 7]             --\n",
       "│    └─Flatten: 2-10                     [1, 3136]                 --\n",
       "│    └─Linear: 2-11                      [1, 128]                  401,536\n",
       "│    └─ReLU: 2-12                        [1, 128]                  --\n",
       "│    └─Dropout: 2-13                     [1, 128]                  --\n",
       "│    └─Linear: 2-14                      [1, 10]                   1,290\n",
       "==========================================================================================\n",
       "Total params: 421,834\n",
       "Trainable params: 421,834\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.60\n",
       "Params size (MB): 1.69\n",
       "Estimated Total Size (MB): 2.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# defining batch\n",
    "batch_size = 64\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "    criterion = criterion.to('cuda')\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e3, 'K parameters')\n",
    "summary(model, input_size=(1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60b9f487-3fd7-4994-ab27-9c185c4a18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print(f'epoch:{epoch}---------')\n",
    "    model.train()\n",
    "\n",
    "    iteration = 0\n",
    "    for images_batch, labels_batch in train_loader:\n",
    "        # clearing the Gradients of the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # prediction for training and validation set\n",
    "        output_train = model(images_batch.to('cuda'))\n",
    "    \n",
    "        # computing the training and validation loss\n",
    "        loss_train = criterion(output_train, labels_batch.to('cuda'))\n",
    "        train_losses.append(loss_train.item())\n",
    "        \n",
    "        # computing the updated weights of all the model parameters\n",
    "        loss_train.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "\n",
    "        iteration += 1\n",
    "        if iteration%100 == 0:\n",
    "            print(f'Iteration : {iteration+1}, train loss:{loss_train.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "711fcb92-af3c-48ae-b863-4e5ea8346e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0---------\n",
      "Iteration : 101, train loss:0.4613\n",
      "Iteration : 201, train loss:0.5249\n",
      "Iteration : 301, train loss:0.5186\n",
      "Iteration : 401, train loss:0.2951\n",
      "Iteration : 501, train loss:0.2569\n",
      "Iteration : 601, train loss:0.3582\n",
      "Iteration : 701, train loss:0.4523\n",
      "Iteration : 801, train loss:0.2440\n",
      "epoch:1---------\n",
      "Iteration : 101, train loss:0.1507\n",
      "Iteration : 201, train loss:0.3635\n",
      "Iteration : 301, train loss:0.2803\n",
      "Iteration : 401, train loss:0.2411\n",
      "Iteration : 501, train loss:0.2371\n",
      "Iteration : 601, train loss:0.2731\n",
      "Iteration : 701, train loss:0.3043\n",
      "Iteration : 801, train loss:0.3512\n",
      "epoch:2---------\n",
      "Iteration : 101, train loss:0.4662\n",
      "Iteration : 201, train loss:0.2810\n",
      "Iteration : 301, train loss:0.2669\n",
      "Iteration : 401, train loss:0.1754\n",
      "Iteration : 501, train loss:0.2241\n",
      "Iteration : 601, train loss:0.1619\n",
      "Iteration : 701, train loss:0.2234\n",
      "Iteration : 801, train loss:0.1672\n",
      "epoch:3---------\n",
      "Iteration : 101, train loss:0.2732\n",
      "Iteration : 201, train loss:0.3347\n",
      "Iteration : 301, train loss:0.2181\n",
      "Iteration : 401, train loss:0.1776\n",
      "Iteration : 501, train loss:0.1336\n",
      "Iteration : 601, train loss:0.1592\n",
      "Iteration : 701, train loss:0.2483\n",
      "Iteration : 801, train loss:0.2049\n",
      "epoch:4---------\n",
      "Iteration : 101, train loss:0.1661\n",
      "Iteration : 201, train loss:0.1911\n",
      "Iteration : 301, train loss:0.2047\n",
      "Iteration : 401, train loss:0.3562\n",
      "Iteration : 501, train loss:0.2921\n",
      "Iteration : 601, train loss:0.1995\n",
      "Iteration : 701, train loss:0.4713\n",
      "Iteration : 801, train loss:0.4572\n",
      "epoch:5---------\n",
      "Iteration : 101, train loss:0.1827\n",
      "Iteration : 201, train loss:0.0788\n",
      "Iteration : 301, train loss:0.1909\n",
      "Iteration : 401, train loss:0.3306\n",
      "Iteration : 501, train loss:0.1479\n",
      "Iteration : 601, train loss:0.3269\n",
      "Iteration : 701, train loss:0.0912\n",
      "Iteration : 801, train loss:0.2669\n",
      "epoch:6---------\n",
      "Iteration : 101, train loss:0.1905\n",
      "Iteration : 201, train loss:0.1986\n",
      "Iteration : 301, train loss:0.0733\n",
      "Iteration : 401, train loss:0.2429\n",
      "Iteration : 501, train loss:0.2258\n",
      "Iteration : 601, train loss:0.2167\n",
      "Iteration : 701, train loss:0.0830\n",
      "Iteration : 801, train loss:0.1925\n",
      "epoch:7---------\n",
      "Iteration : 101, train loss:0.0900\n",
      "Iteration : 201, train loss:0.2680\n",
      "Iteration : 301, train loss:0.2033\n",
      "Iteration : 401, train loss:0.3413\n",
      "Iteration : 501, train loss:0.2576\n",
      "Iteration : 601, train loss:0.1160\n",
      "Iteration : 701, train loss:0.1322\n",
      "Iteration : 801, train loss:0.1100\n",
      "epoch:8---------\n",
      "Iteration : 101, train loss:0.1689\n",
      "Iteration : 201, train loss:0.2056\n",
      "Iteration : 301, train loss:0.1443\n",
      "Iteration : 401, train loss:0.2053\n",
      "Iteration : 501, train loss:0.1043\n",
      "Iteration : 601, train loss:0.1567\n",
      "Iteration : 701, train loss:0.0776\n",
      "Iteration : 801, train loss:0.1141\n",
      "epoch:9---------\n",
      "Iteration : 101, train loss:0.2510\n",
      "Iteration : 201, train loss:0.2105\n",
      "Iteration : 301, train loss:0.1754\n",
      "Iteration : 401, train loss:0.1819\n",
      "Iteration : 501, train loss:0.0749\n",
      "Iteration : 601, train loss:0.1136\n",
      "Iteration : 701, train loss:0.1080\n",
      "Iteration : 801, train loss:0.1863\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71e66565-84f5-419c-941f-f84cd2b1b744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_loader_single_batch = DataLoader(test_set, batch_size=len(test_set), shuffle=False)\n",
    "\n",
    "# Function to retrieve all data in one batch\n",
    "def get_all_data_single_batch(dataloader):\n",
    "    all_images, all_labels = next(iter(dataloader))  # Retrieve the single batch\n",
    "    return all_images, all_labels\n",
    "\n",
    "# Retrieve all images and labels\n",
    "all_validate_images, all_validate_labels = get_all_data_single_batch(validate_loader_single_batch)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_val = model(all_validate_images.to('cuda'))\n",
    "\n",
    "softmax = torch.exp(output_val).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "predictions = np.argmax(prob, axis=1)\n",
    "val_accu = accuracy_score(all_validate_labels, predictions)\n",
    "val_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6ad0b88-6ed4-4bcf-b9cf-f794144658ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2621687948703766"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_val = model(all_validate_images.to('cuda'))\n",
    "    loss_val = criterion(output_val, all_validate_labels.to('cuda'))\n",
    "loss_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "850e9315-042b-4ffc-a674-f35c7e8392ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9125, 0.2625797390937805)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accu, loss_val.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
